{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction as aF\n",
    "from pathlib import Path\n",
    "\n",
    "from pandas_ml import ConfusionMatrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, recall_score\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   index       file_name\n",
       " 0      0  train_0001.wav\n",
       " 1      1  train_0002.wav\n",
       " 2      2  train_0003.wav\n",
       " 3      3  train_0004.wav\n",
       " 4      4  train_0005.wav,    index  emotion\n",
       " 0      0  neutral\n",
       " 1      1  neutral\n",
       " 2      2  neutral\n",
       " 3      3  neutral\n",
       " 4      4  neutral)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = Path('../data/')\n",
    "df_labels = labels = pd.read_csv(path_data/'ComParE2018_AtypicalAffect.txt', sep=\"\\t\")\n",
    "df_labels['subset'] = df_labels['file_name'].str.split('_').apply(lambda x: x[0])\n",
    "df_labels.head()\n",
    "\n",
    "\n",
    "# & \n",
    "#                                    (df_labels['emotion'] == 'neutral')\n",
    "X_train, y_train = ((df_labels.loc[(df_labels['subset']=='train')][['file_name']]), \n",
    "                    df_labels.loc[df_labels['subset']=='train']['emotion'])\n",
    "\n",
    "X_devel, y_devel = (df_labels.loc[df_labels['subset']=='devel'][['file_name']], \n",
    "                    df_labels.loc[df_labels['subset']=='devel']['emotion'])\n",
    "\n",
    "#train and development\n",
    "X_train_all, y_train_all = (pd.concat([X_train, X_devel], axis=0).reset_index(), \n",
    "                            pd.concat([y_train, y_devel], axis=0).reset_index())\n",
    "\n",
    "\n",
    "X_test, y_test = (df_labels.loc[df_labels['subset']=='test'][['file_name']], \n",
    "                    df_labels.loc[df_labels['subset']=='test']['emotion'])\n",
    "\n",
    "X_train_all.head(), y_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file_name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>raw_data</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train_0001.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>[8, -16, -121, -137, -27, 25, -6, -85, -84, 13...</td>\n",
       "      <td>2.149812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train_0002.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>[364, 614, 507, 569, 466, 485, 458, 422, 401, ...</td>\n",
       "      <td>1.263750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train_0003.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-15, -17, 21, 14, 18, 25, 22, 45, 49, 22, 27,...</td>\n",
       "      <td>0.817125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>train_0004.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-819, -1333, -1253, -1463, -1517, -1561, -164...</td>\n",
       "      <td>0.758125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train_0005.wav</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-100, -67, -311, -415, -351, -369, -362, -302...</td>\n",
       "      <td>0.770312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       file_name  sample_rate  \\\n",
       "0      0  train_0001.wav        16000   \n",
       "1      1  train_0002.wav        16000   \n",
       "2      2  train_0003.wav        16000   \n",
       "3      3  train_0004.wav        16000   \n",
       "4      4  train_0005.wav        16000   \n",
       "\n",
       "                                            raw_data  duration  \n",
       "0  [8, -16, -121, -137, -27, 25, -6, -85, -84, 13...  2.149812  \n",
       "1  [364, 614, 507, 569, 466, 485, 458, 422, 401, ...  1.263750  \n",
       "2  [-15, -17, 21, 14, 18, 25, 22, 45, 49, 22, 27,...  0.817125  \n",
       "3  [-819, -1333, -1253, -1463, -1517, -1561, -164...  0.758125  \n",
       "4  [-100, -67, -311, -415, -351, -369, -362, -302...  0.770312  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ReadRawData(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_c = X.copy()\n",
    "        df_sample_data = X_c['file_name'].apply(lambda x: audioBasicIO.readAudioFile(path_data/'wav'/x))\n",
    "        X_c['sample_rate'] = df_sample_data.apply(lambda x: x[0])\n",
    "        X_c['raw_data'] = df_sample_data.apply(lambda x: x[1])\n",
    "        X_c['duration'] = X_c['raw_data'].apply(lambda x: x.size)/X_c['sample_rate']\n",
    "        return X_c\n",
    "        \n",
    "rrd = ReadRawData()\n",
    "# X_train = rrd.fit_transform(X_train)\n",
    "# X_devel =rrd.transform(X_devel)\n",
    "X_train_all = rrd.fit_transform(X_train_all)\n",
    "X_test =rrd.transform(X_test)\n",
    "X_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyAudioAnalysisFeaturesFactory(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 limit_to=4, #parameter to control where to truncate (or pad)\n",
    "                 pad=['resize', 'zero', 'mean', 'stat'][0], # what kind of padding to use\n",
    "                 frame_size=0.05, #PyAudio default\n",
    "                 frame_step=0.025,#PyAudio default\n",
    "                 keep_duration=True #to keep duration as a feature\n",
    "                ):\n",
    "        self.limit_to, self.pad = limit_to, pad\n",
    "        self.frame_size, self.frame_step = frame_size, frame_step\n",
    "        self.keep_duration = keep_duration\n",
    "        self.key = f'{limit_to}_{pad}_{frame_size}_{frame_step}_{keep_duration}'\n",
    "        self.counter = 0\n",
    "\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_c = X.copy()\n",
    "        if self.pad == 'stat':\n",
    "            features = X_c.apply(lambda x: self.add_features_functionals((x['sample_rate'], \n",
    "                                                                          x['raw_data'])), \n",
    "                                 axis=1)\n",
    "            features = pd.DataFrame(features.values.tolist())\n",
    "        else:\n",
    "            features = X_c.apply(lambda x: self.add_features((x['sample_rate'], x['raw_data'])), axis=1)\n",
    "            # these steps are just for getting the column names\n",
    "            x = X_c['raw_data'].iloc[0]\n",
    "            fs = X_c['sample_rate'].iloc[0]\n",
    "            s, t = aF.stFeatureExtraction(np.resize(x,(fs*self.limit_to,)),\n",
    "                                          fs,\n",
    "                                          self.frame_size*fs,\n",
    "                                          self.frame_step*fs)\n",
    "            col_names = np.array([f'{name}_{i}' for i in range(s.shape[1]) for name in t]).reshape(-1)\n",
    "            features = pd.DataFrame(features.values.tolist(), columns=col_names)\n",
    "        \n",
    "        if self.keep_duration:\n",
    "            features['duration'] = X_c['duration']\n",
    "        return features.astype(np.float32)\n",
    "            \n",
    "            \n",
    "    def add_features(self, res):\n",
    "        if self.counter%20 == 0:\n",
    "            print(self.counter)\n",
    "        self.counter += 1\n",
    "        fs,x = res\n",
    "        diff = (self.limit_to*fs)-x.shape[0]\n",
    "        if self.pad == 'resize':\n",
    "            x = np.resize(x,(fs*self.limit_to,))\n",
    "        elif self.pad == 'zero':\n",
    "            x = np.hstack([np.zeros(diff), x]) if diff>0 else x[:(self.limit_to*fs)]\n",
    "        else:\n",
    "            x = np.hstack([np.repeat(x.mean(), diff), x]) if diff>0 else x[:(self.limit_to*fs)]\n",
    "            \n",
    "        s,t = aF.stFeatureExtraction(x,fs,self.frame_size*fs,self.frame_step*fs)\n",
    "        s = s.T.reshape(-1)\n",
    "        return s\n",
    "    \n",
    "    def add_features_functionals(self, res):\n",
    "        fs,x = res\n",
    "        s,t = aF.stFeatureExtraction(x,fs,self.frame_size*fs,self.frame_step*fs)\n",
    "        summarized_functionals = np.hstack([\n",
    "            s.mean(axis=1), \n",
    "            s.min(axis=1), \n",
    "            s.max(axis=1), \n",
    "            s.std(axis=1)\n",
    "        ])\n",
    "        return summarized_functionals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "# feature_transform_params = {\n",
    "#     'limit_to': [2, 4, 6],\n",
    "#     'pad': ['resize', 'zero', 'mean']\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# feature_transform_param_combs = [dict(zip(feature_transform_params.keys(),v))\n",
    "#                                  for v in product(*feature_transform_params.values())]\n",
    "    \n",
    "\n",
    "# feature_dict = dict()\n",
    "\n",
    "# for i in feature_transform_param_combs:\n",
    "#     print(i)\n",
    "#     paaff = PyAudioAnalysisFeaturesFactory(**i)\n",
    "#     feature_dict[paaff.key] = paaff.fit_transform(X_train_all)\n",
    "\n",
    "paaff = PyAudioAnalysisFeaturesFactory(pad='resize')\n",
    "paaff.fit_transform(X_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2_resize_0.05_0.025_True', '2_zero_0.05_0.025_True', '2_mean_0.05_0.025_True', '4_resize_0.05_0.025_True', '4_zero_0.05_0.025_True', '4_mean_0.05_0.025_True', '6_resize_0.05_0.025_True', '6_zero_0.05_0.025_True', '6_mean_0.05_0.025_True'])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing the dictionary for future use\n",
    "\n",
    "print(feature_dict.keys())\n",
    "\n",
    "with open(path_data/'feature_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(feature_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open(path_data/'filename.pickle', 'rb') as handle:\n",
    "#     feature_dict = pickle.load(handle)\n",
    "\n",
    "\n",
    "# paf = PyAudioAnalysisFeatures()\n",
    "# X_train = paf.transform(X_train)\n",
    "# X_devel = paf.transform(X_devel)\n",
    "# X_test = paf.transform(X_test)\n",
    "\n",
    "# X_train.to_csv(path_data/'train_4-sec.csv')\n",
    "# X_test.to_csv(path_data/'test_4-sec.csv')\n",
    "# X_devel.to_csv(path_data/'devel_4-sec.csv')\n",
    "\n",
    "# X_train = pd.read_csv(path_data/'train_4-sec.csv')\n",
    "# X_test = pd.read_csv(path_data/'test_4-sec.csv')\n",
    "# X_devel = pd.read_csv(path_data/'devel_4-sec.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyAudioAnalysisFeatures(PyAudioAnalysisFeaturesFactory, BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        PyAudioAnalysisFeaturesFactory.__init__(self, **kwargs)\n",
    "        \n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_base = feature_dict[self.key]\n",
    "        return X_base.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_0</th>\n",
       "      <th>energy_0</th>\n",
       "      <th>energy_entropy_0</th>\n",
       "      <th>spectral_centroid_0</th>\n",
       "      <th>spectral_spread_0</th>\n",
       "      <th>spectral_entropy_0</th>\n",
       "      <th>spectral_flux_0</th>\n",
       "      <th>spectral_rolloff_0</th>\n",
       "      <th>mfcc_1_0</th>\n",
       "      <th>mfcc_2_0</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma_5_158</th>\n",
       "      <th>chroma_6_158</th>\n",
       "      <th>chroma_7_158</th>\n",
       "      <th>chroma_8_158</th>\n",
       "      <th>chroma_9_158</th>\n",
       "      <th>chroma_10_158</th>\n",
       "      <th>chroma_11_158</th>\n",
       "      <th>chroma_12_158</th>\n",
       "      <th>chroma_std_158</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227785</td>\n",
       "      <td>0.329161</td>\n",
       "      <td>0.456821</td>\n",
       "      <td>0.480601</td>\n",
       "      <td>0.488110</td>\n",
       "      <td>0.481852</td>\n",
       "      <td>0.401752</td>\n",
       "      <td>0.215269</td>\n",
       "      <td>0.101377</td>\n",
       "      <td>0.103880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.035767</td>\n",
       "      <td>0.031810</td>\n",
       "      <td>0.024497</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.038841</td>\n",
       "      <td>0.039237</td>\n",
       "      <td>2.149812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075094</td>\n",
       "      <td>0.072591</td>\n",
       "      <td>0.092616</td>\n",
       "      <td>0.147685</td>\n",
       "      <td>0.200250</td>\n",
       "      <td>0.125156</td>\n",
       "      <td>0.052566</td>\n",
       "      <td>0.061327</td>\n",
       "      <td>0.060075</td>\n",
       "      <td>0.055069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015770</td>\n",
       "      <td>0.018118</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>0.040933</td>\n",
       "      <td>0.051808</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.034263</td>\n",
       "      <td>0.028873</td>\n",
       "      <td>0.817125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.125156</td>\n",
       "      <td>0.200250</td>\n",
       "      <td>0.245307</td>\n",
       "      <td>0.161452</td>\n",
       "      <td>0.077597</td>\n",
       "      <td>0.087610</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.105131</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058274</td>\n",
       "      <td>0.069391</td>\n",
       "      <td>0.061403</td>\n",
       "      <td>0.034582</td>\n",
       "      <td>0.050379</td>\n",
       "      <td>0.015063</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>0.033224</td>\n",
       "      <td>0.041645</td>\n",
       "      <td>0.770312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 5407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      zcr_0  energy_0  energy_entropy_0  spectral_centroid_0  \\\n",
       "0  0.227785  0.329161          0.456821             0.480601   \n",
       "2  0.075094  0.072591          0.092616             0.147685   \n",
       "4  0.125156  0.200250          0.245307             0.161452   \n",
       "\n",
       "   spectral_spread_0  spectral_entropy_0  spectral_flux_0  spectral_rolloff_0  \\\n",
       "0           0.488110            0.481852         0.401752            0.215269   \n",
       "2           0.200250            0.125156         0.052566            0.061327   \n",
       "4           0.077597            0.087610         0.106383            0.105131   \n",
       "\n",
       "   mfcc_1_0  mfcc_2_0  ...  chroma_5_158  chroma_6_158  chroma_7_158  \\\n",
       "0  0.101377  0.103880  ...      0.020262      0.018331      0.019932   \n",
       "2  0.060075  0.055069  ...      0.015770      0.018118      0.031636   \n",
       "4  0.071339  0.058824  ...      0.058274      0.069391      0.061403   \n",
       "\n",
       "   chroma_8_158  chroma_9_158  chroma_10_158  chroma_11_158  chroma_12_158  \\\n",
       "0      0.035767      0.031810       0.024497       0.028909       0.038841   \n",
       "2      0.040933      0.051808       0.070929       0.050378       0.034263   \n",
       "4      0.034582      0.050379       0.015063       0.019894       0.033224   \n",
       "\n",
       "   chroma_std_158  duration  \n",
       "0        0.039237  2.149812  \n",
       "2        0.028873  0.817125  \n",
       "4        0.041645  0.770312  \n",
       "\n",
       "[3 rows x 5407 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PyAudioAnalysisFeatures().transform(X_train.loc[[0,2,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-5903fc9f3599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#                         iid=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_pipeline = pipeline.Pipeline([\n",
    "    ('features', PyAudioAnalysisFeatures()),\n",
    "    ('pca', PCA(n_components=500)),\n",
    "    ('model', AdaBoostClassifier(DecisionTreeClassifier(class_weight={'neutral': 100000, \n",
    "                                                                      'happy': 100, \n",
    "                                                                      'sad': 1, \n",
    "                                                                      'angry':1}), \n",
    "                                 n_estimators=100, learning_rate=10.0))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [15, 50, 100, 250, 500],\n",
    "    'model__class_weight': [\n",
    "                        {'neutral': 1, 'happy': 1, 'sad': 100000, 'angry':100000},\n",
    "                        {'neutral': 100000, 'happy': 100000, 'sad': 1, 'angry':1}\n",
    "                    ],\n",
    "    'model__learning_rate': [0.1, 1, 10.0]\n",
    "}\n",
    "\n",
    "for k,v in feature_transform_params:\n",
    "    param_grid['features__'+k] = v\n",
    "    \n",
    "# custom scoring - Unweighted Average Recall (from the paper),  \n",
    "# because our data is imbalanced\n",
    "uar = make_scorer(recall_score, average='macro')\n",
    "\n",
    "model_pipeline_cv = GridSearchCV(\n",
    "    estimator= model_pipeline, #use the model\n",
    "    param_grid=param_grid, # generate combinations from the parameter grid\n",
    "    scoring=uar, #UAR to pick the best params\n",
    "    n_jobs=4, # use these many cores for faster parallel processing\n",
    "    cv=5, # k fold cv\n",
    "    refit=True, # refit the best parameters on all of the data\n",
    "    verbose=50, #give detailed progress\n",
    "    iid=True)\n",
    "\n",
    "model_pipeline_cv.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    \n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def reporting(y_test,y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, target_names=np.unique(y_train))\n",
    "    print(confusion_matrix)\n",
    "    print(\"\\n\",classification_report(y_test,y_pred))\n",
    "    print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporting(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "457px",
    "left": "1577px",
    "right": "20px",
    "top": "120px",
    "width": "323px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
